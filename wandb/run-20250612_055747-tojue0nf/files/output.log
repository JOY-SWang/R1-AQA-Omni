  0%|                                                                                                                                       | 0/1000 [00:00<?, ?it/s]Traceback (most recent call last):
audio===================**
([array([-0.00595093, -0.0161438 , -0.02017212, ..., -0.17193604,
        0.10983276, -0.04824829], dtype=float32)], None, None)
text===================**
["<|im_start|>system\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\n<|im_start|>user\n<|audio_bos|><|AUDIO|><|audio_eos|>What's moving in the audio? Please choose the answer from the following options: ['lathe rotation sound', 'motorcycle', 'metro', 'train']. Output the final answer in <answer> </answer>.<|im_end|>\n<|im_start|>assistant\n"]
  File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/train.py", line 79, in <module>
    main()
  File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/train.py", line 74, in main
    trainer.train()
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
    return inner_training_loop(
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3745, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/trainer/grpo_trainer.py", line 392, in compute_loss
    prompt_inputs = self.processing_class(
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py", line 162, in __call__
    audio_inputs = self.feature_extractor(audio, **output_kwargs["audio_kwargs"])
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/models/whisper/feature_extraction_whisper.py", line 293, in __call__
    padded_inputs = self.pad(
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py", line 209, in pad
    outputs = self._pad(
  File "/root/miniconda3/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py", line 290, in _pad
    processed_features[self.model_input_names[0]] = np.pad(
  File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_arraypad_impl.py", line 761, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_arraypad_impl.py", line 534, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_stride_tricks_impl.py", line 424, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_stride_tricks_impl.py", line 359, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/train.py", line 79, in <module>
[rank0]:     main()
[rank0]:   File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/train.py", line 74, in main
[rank0]:     trainer.train()
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/trainer.py", line 3745, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/fs-computility/niuyazhe/wangjieyi/code/r1-aqa-main-v1/src/trainer/grpo_trainer.py", line 392, in compute_loss
[rank0]:     prompt_inputs = self.processing_class(
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py", line 162, in __call__
[rank0]:     audio_inputs = self.feature_extractor(audio, **output_kwargs["audio_kwargs"])
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/models/whisper/feature_extraction_whisper.py", line 293, in __call__
[rank0]:     padded_inputs = self.pad(
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py", line 209, in pad
[rank0]:     outputs = self._pad(
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py", line 290, in _pad
[rank0]:     processed_features[self.model_input_names[0]] = np.pad(
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_arraypad_impl.py", line 761, in pad
[rank0]:     pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_arraypad_impl.py", line 534, in _as_pairs
[rank0]:     return np.broadcast_to(x, (ndim, 2)).tolist()
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_stride_tricks_impl.py", line 424, in broadcast_to
[rank0]:     return _broadcast_to(array, shape, subok=subok, readonly=True)
[rank0]:   File "/root/miniconda3/lib/python3.10/site-packages/numpy/lib/_stride_tricks_impl.py", line 359, in _broadcast_to
[rank0]:     it = np.nditer(
[rank0]: ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)
